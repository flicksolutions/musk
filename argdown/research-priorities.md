```
===
outputPath: "../output/research-priorities"
===
```

\# Short-Term

\## Law and Ethics

\### Haftung autonomer Transportmittel

[Haftung]\: Die Haftung bei Schäden durch autonome Anwendungen ist nicht geklärt (Calo 2014)

[Trolley-Problem]\: Trolley-Problem bei autonomen Fahrzeugen (Vladeck 2014)

\### Machine Ethics

[Marktvolatilität]\: AI-Software im Gebrauch bei Börsen kann zu Marktvolatilität führen (Calo 2014)

[Bots an der Börse]\: AI-Bots an der Börse übersteigen den Mensch an Effizienz, Geschwindigkeit und Volumen (Calo 2014)

[Insider-Trading]\: Insider-Trading durch AI-Bots durch Abarbeitung hoher Volumen an Informationen (Calo 2014)

[Physischer Schaden]\: Roboter können physikalischen Schaden verursachen (Calo 2014)

[ELD]\: Durch physikalischen Schaden kann die "Economic Loss Doctrine" nicht geltend gemacht werden (Calo 2014)

\### Autonomous Weapons

[nicht-verboten]\: Der Einsatz autonomer Waffen ist durch kein international bindendes Instrument verboten (Docherty 2012)
Auf nationaler Ebene existieren keine Gesetze, welche Entwicklung und Einsatz autonomer Waffen verbieten (Docherty 2012)

[kein CoC]\: Entwickler halten sich nicht an einen Code of Conduct, so dass Entwicklung mit den Gesetzen und ethischen Regeln übereinstimmen (Docherty 2012)

\### Professional Ethics

[legaler Status]\: Der Legale Status der AI ist nicht bestimmt (Calo 2015)

[Right to Copy]\: Right to copy, right to participate-Dilemma (Calo 2015)

\#### Policy Questions

[keine Richtlinien]\: Es existiert kein staatlicher Körper, der Richtlinien erstellt (Calo 2014)

[nicht vorbereitet]\: Wir sind nicht auf die Gefahren vorbereitet (Calo 2014)

[Staat arbeitet ineffizient]\: Verschiedene staatliche Körper arbeiten nicht effizient miteinander (Calo 2014)


\# Optimizing AI’s Economic Impact \{isGroup: true\}

Hier finden sich vorallem 2 Paper die Gefahren aufzeigen. Es geht dabei vor allem darum, dass dem Grossteil der Gesellschaft die Arbeitslosigkeit droht.

\## Mokyr, J. 2014. Secular Stagnation? Not in Your Life.  \{isGroup: true\}

[GDP ist falsches Messinstrument]\: Why the gloominess of my colleagues? Part of the story is that economists are trained to look at aggregate statistics like GDP per capita and its derivatives such as factor productivity. These measures were designed for a steel-and-wheat economy, not one in which information and data are the most dynamic sector. Many of the new goods and services are expensive to design, but once they work, they can be copied at very low or zero costs. That means they tend to contribute little to measured output even if their impact on consumer welfare is very large. Dealing with altogether new goods and services was not what these numbers were designed for, despite the heroic efforts by BLS statisticians. The aggregative statistics miss much of what is interesting.

\## The Second Machine Age: Work, Progress and Prosperity in a Time of Brilliant Technologies  \{isGroup: true\}

<Power Law>[@brynjolfssonSecondMachineAge2014, chap. 10 ] & @mokyrSecularStagnationNot2014
(1) "Normale" Wirtschaft folgt einer normalen Verteilung, weil die Nachfrage nicht von einem Anbieter befriedigt werden kann.
(2) Ein Anbieter von digitalen Produkten kann theoretisch die ganze Nachfrage nach einem Produkt befriedigen.
(3) Durch die Vernetzung der Welt (globaler Markt), können alle bestehenden Produkte verglichen werden, alle Produkte müssen also mit dem Besten konkurrieren. Dies führt zu einem Potenzgesetz.
(4) Die Digitalisierung führt zu einer grösseren Vernetzung der Welt.
(5) Netzwerke und Standards werden wichtiger in einer digitalen Welt.
(6) Netzwerke und Standards fördern ein Potenzgesetz.

-----
(7) Die Digitalisierung verändert die ökonomischen Prozesse so, dass die Verteilung des Reichtums einem Potenzgesetz ([Pareto-Verteilung](https://www.youtube.com/watch?v=fCn8zs912OE)) folgt und nicht mehr einer Normalverteilung (Glockenkurve).
(8) Durch die Konzentration von Reichtum wird ein positiver Feedback-Loop in Gang gesetzt, der den Effekt (Potenzgesetz) noch verstärkt [@brynjolfssonSecondMachineAge2014, p. 135]
(9) Durch die Entwicklung von AI werden weitere Märkte vernetzt (globalisiert). (z.B. Übersetzung)
(10) Durch die Entwicklung von AI (Roboter) werden analoge Dienstleistungen zu digitalen. → Somit kann die ganze Nachfrage von einem Anbieter befriedigt werden.

-----
(11) Die Entwicklung von AI führt dazu, dass die Wirtschaft noch stärker einem Potenzgesetz folgt.
(x) 

-----
(12) [Armut]

<Technological Unemployment> [@brynjolfssonSecondMachineAge2014, p. 153] & @mokyrSecularStagnationNot2014
(1) Technische Entwicklungen führen zu Jobverlusten.
(2) Jobverluste werden nach einer gewissen Zeitdauer *t* ausgeglichen, weil die technischen Entwicklungen neue Berufsfelder entstehen lassen.
(3) Durch die Entwicklung von AI wird die technologische Entwicklung derart beschleunigt, dass *t* immer weiter wächst.

-----
(4) Die Entwicklung von AI führt zu permanenten Jobverlusten. - *t* geht gegen unendlich.
(5) Das Einkommen eines grossen Teils der Bevölkerung hängt von ihrem Job ab.

-----
(6) [Armut]: Die Entwicklung von AI führt zu extremer Armut bei einem grossen Teil der Bevölkerung.

<Android-Experiment> @brynjolfssonSecondMachineAge2014
(1) Es gibt Androiden (Menschenähnliche Roboter)
(2) Die Androiden können alle Arbeiten eines menschlichen Arbeiters verrichten.
~(3) Die Androiden können selbst andere Androiden herstellen.~
(4) Die Androiden sind günstig herstellbar.
(5) Es gibt ein unendlich grosses Angebot an Androiden.
(6) Die Betriebskosten der Androiden sind fast Null.
(7) Die Androiden arbeiten 24/7.

-----
(6) Produktivität und und Produktion steigen extrem.
(7) Preise für Produkte in einem kompetitiven Markt sind nahe an den Preisen der Rohstoffe. //follows from up
(8) Es würden nur noch Androiden und keine Menschen mehr eingestellt. //follows from up

-----
(9) Die Besitzer der Androiden, anderer Kapitalanlagen und natürlicher Ressourcen beanspruchen den kompletten Wert der Wirtschaft für sich und sind auch die einzigen Konsumenten.
(10) Menschen ohne Kapitalanlagen, Androiden und natürliche Ressourcen haben nur Ihre Arbeit anzubieten und diese ist wertlos geworden. //follows from up

-----
(11) [Armut]


\## Disruptive technologies: Advances that will transform life, business, and the global economy  \{isGroup: true\}

[Disruptive technologies]\: The benefits of the mobile Internet and cloud computing are accompanied by rising risks of security and privacy breaches. Objects and machines under the control of computers across the Web (the Internet of Things) can also be hacked, exposing factories, refineries, supply chains, power plants, and transportation networks to new risks. Next-generation genomics has the potential to grant new powers over biology, but these powers could be abused to disastrous effect. Low-cost desktop gene-sequencing machines will not only put the power of genomics in doctor offices, but also potentially in the hands of terrorists. Even well-intentioned experiments in garages using inexpensive sequencing and DNA synthesis equipment could result in the production and release of dangerous organisms. And nanomaterials offer great promise, but more research will be required to fully ascertain their potential impact on health. It will be up to business leaders, policy makers, and societies to weigh these risks and navigate a path that maximizes the value of these technologies while avoiding their dangers.

\# Computer Science Research for Robust AI  \{isGroup: true\}

[Robustheit]\: AI ist nicht robust und deshalb nicht sicher [@russellResearchPrioritiesRobust2015, p. 107]

[Verifikation]\: Ganze AI-Agents sind nicht formal verifizierbar: 
> we lack the formal algebra to properly define, explore,
and rank the space of designs. Perhaps the most salient difference between verification of traditional software and verification of AI systems is that the correctness of traditional software is defined with respect to a fixed and known machine model, whereas AI systems — especially robots and other embodied systems — operate in environments that are at best partially known by the system designer. [@russellResearchPrioritiesRobust2015, p. 108]
Das Ganze gestaltet sich noch schwerer bei AI die learning Algorithmen anwendet.

[Validity]\: Unsere Anforderungen an die AI können falsch formuliert sein und so könnten sich AI-Agents unpassend verhalten.
> Such specification errors are ubiquitous in software
> verification, where it is commonly observed that
> writing correct specifications can be harder than writing
> correct code. Unfortunately, it is not possible to
> verify the specification: the notions of beneficial and
> desirable are not separately made formal, so one cannot
straightforwardly prove that satisfying ψ necessarily
leads to desirable behavior and a beneficial
agent.
 [@russellResearchPrioritiesRobust2015, p. 108]
 
 [moral decisions von Maschinen]\: Aufgrund Ihrer Komplexität, Vernetztheit und Kompetenzen müssen Systeme selbst ethische Entscheidungen treffen. [@wallachMoralMachinesTeaching2008, p.4]
 <AI muss Entscheidungen treffen> [@wallachMoralMachinesTeaching2008, p.39]
 Wenn Systeme aus verschiedenen möglichen Optionen auswählen, treffen sie Entscheidungen.
 Ob diese Entscheidungen ethisch gut oder schlecht sind, hängt von den Werten ab, die der Ingenieur ihnen beibringt.
 Weil Systeme modular aufgebaut sind, kann niemand vorhersagen, wie die Systeme mit der Umwelt interagieren.
 
 

<Vorteile verhindern Moratorium> [@wallachMoralMachinesTeaching2008, p.5, chap. 3]
(1) Maschinen, die moralisch-relevante Entscheidungen treffen müssen, können grosse Vorteile bringen.
(2) Der Markt und die Politik verlangen nach diesen Vorteilen.
(3) Wenn eine Maschine nicht mit moralischen Entscheiden umgehen kann, trifft Sie schlechte moralische Entscheide.

----
(4) Es ist ~notwendig~, dass man AI mit der Fähigkeit, mit moralischen Entscheidungen umzugehen, entwickelt.

[Abtreten von moralischen Entscheidungen]\: 
> Some concerns, for example whether AMAs will lead humans to abrogate responsibility
to machines, seem particularly pressing.
> — [@wallachMoralMachinesTeaching2008, p. 9] & [@wallachMoralMachinesTeaching2008, chap. 3]

<Decision Support Tools>
DST unterstützen Menschen dabei Entscheidungen zu treffen.
Wenn DST gut funktionieren, fangen Menschen an, ihre Entscheidungen nicht mehr selbst zu treffen, sondern überlassen die Entscheidungen den DST.

-----
Wenn DST gut funktionieren, kontrollieren sie selbst Entscheidungsprozesse.



[Cyberattacken]\:
   > As AI systems are used in an increasing number of critical roles, they will take up an increasing proportion of cyberattack surface area. It is also probable that AI and machine-learning techniques will themselves be used in cyberattacks.
>(...)It is not implausible that cyberattack between states and private actors will be a risk factor for harm from near-future AI systems, motivating research on preventing harmful events.
> — [@russellResearchPrioritiesRobust2015, p. 109]




\# Long-Term  \{isGroup: true\}

\## Verification  \{isGroup: true\}

[selbst-veränderung]\: If humanity creates an agent that attains superintelligence through a sequence of successive self-improvments, the resulting system may be quite different from the initial verified system. (Fallenstein and Soares 2014)

\## Validity  \{isGroup: true\}

[treacherous turn]\: The treacherous turn—While weak, an AI behaves cooperatively (increasingly so, as it gets smarter). When the AI gets sufficiently strong—without warning or provocation—it strikes, forms a singleton, and begins directly to optimize the world according to the criteria implied by its final values. (Bostrom 2014)

[unfriendly AI]\: An unfriendly AI of sufficient intelligence realizes that its unfriendly final goals will be best realized if it behaves in a friendly manner initially. (Bostrom 2014)

\## Security  \{isGroup: true\}

[confinement]\: An unconfined AI can transmit information to any other program. (Yampolskiy 2012)

\## Control  \{isGroup: true\}

[resistance]\: As artificially intelligent systems grow in intelligence and capability, some of their available options may allow them to resist intervention by their programmers. (Soares et al 2015)

[intelligence explosion]\: The design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an "intelligence explosion" and the intelligence of man would be left far behind. (Good 1963)

[ultraintelligence]\: The first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control. (Good 1963)

[change]\: We are on the edge of change comparable to the rise of human life on earth. (Vinge 1993)

[singularity]\: The singularity can change everything we know in a matter of hours (Vinge 1993)

[understanding of nature]\: With increasing intelligence may come not merely a quantitative improvement in the ability to attain the same old goals, but a qualitatively different understanding of the nature of reality that reveals the old goals to be misguided, meaningless or even undefined. (Tegmark 2015)

\# References  \{isGroup: false\}