

[Gefahren der AI-Entwicklung]
    +  [Short-Term]
        +   [Law and Ethics]
            +   AI-Entwicklung bringt Gefahren mit sich, wenn sie nicht durch Gesetze eingeschränkt wird
                +   Haftung autonomer Transportmittel
                    +   Die Haftung bei Schäden durch autonome Anwendungen ist nicht geklärt
                    +   Trolley-Problem bei autonomen Fahrzeugen
                +   Machine Ethics
                    +   AI-Software im Gebrauch bei Börsen kann zu Marktvolatilität führen
                        +   AI-Bots an der Börse übersteigen den Mensch an Effizienz, Geschwindigkeit und Volumen
                        +   Insider-Trading durch AI-Bots durch Abarbeitung hoher Volumen an Informationen
                    +   Roboter können physikalischen Schaden verursachen
                        +   Durch physikalischen Schaden kann die "Economic Loss Doctrine" nicht geltend gemacht werden
                +   Autonomous Weapons
                    +   Der Einsatz autonomer Waffen ist durch kein international bindendes Instrument verboten
                    +   Auf nationaler Ebene existieren keine Gesetze, welche Entwicklung und Einsatz autonomer Waffen verbieten
                    +   Entwickler halten sich nicht an einen Code of Conduct, so dass Entwicklung mit den Gesetzen und ethischen Regeln übereinstimmen
                +   Privacy
                +   Professional Ethics  
                    +   Der Legale Status der AI ist nicht bestimmt
                    +   Right to copy, right to participate-Dilemma
                +   Policy Questions
                    +   Es existiert kein staatlicher Körper, der Richtlinien erstellt
                    +   Wir sind nicht auf die Gefahren vorbereitet
                    +   Verschiedene staatliche Körper arbeiten nicht effizient miteinander
        +   [Optimizing AI's Economic Impact]
            +   Labor Market Forecasting
            +   Other Market Disruptions
            +   Policy for Managing Adverse effects
            +   Economic Measures
        +   [Computer Science Research for Robust AI]
                +   Verification
                +   Validity
                +   Security
                +   Control
    +   [Long-Term]
        +   Verification
            +   If humanity creates an agent that attains superintelligence through a sequence of successive self-improvments, the resulting system may be quite different from the initial verified system.
        +   Validity
            +   The treacherous turn—While weak, an AI behaves cooperatively (increasingly so, as it gets smarter). When the AI gets sufficiently strong—without warning or provocation—it strikes, forms a singleton, and begins directly to optimize the world according to the criteria implied by its final values.
            +   An unfriendly AI of sufficient intelligence realizes that its unfriendly final goals will be best realized if it behaves in a friendly manner initially.
        +   Security
            +   An unconfined AI can transmit information to any other program.
        +   Control
            +   As artificially intelligent systems grow in intelligence and capability, some of their available options may allow them to resist intervention by their programmers.
            +   The design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an "intelligence explosion" and the intelligence of man would be left far behind.
            +   The first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.
            +   We are on the edge of change comparable to the rise of human life on earth.
            +   The singularity can change everything we know in a matter of hours
            +   With increasing intelligence may come not merely a quantitative improvement in the ability to attain the same old goals, but a qualitatively different understanding of the nature of reality that reveals the old goals to be misguided, meaningless or even undefined.

