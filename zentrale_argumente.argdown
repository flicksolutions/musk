===
model:
    removeTagsFromText: false
===

[Zentrale These]: Eine General AI stellt eine Gefahr für unsere Existenz dar.

[Neuralink]: Mit einem Human-Machine-Interface können wir "along the ride" mitgenommen werden mit der GAI.

[extraterrestrische Zivilisation]: Mit der Errichtung einer Zivilisation auf dem Mars, haben wir eine Backup-Zivilisation, falls wir alle sterben

[Einschränkung]: Staatliche oder Super-staatliche Aufsichtsbehörden schränken die Entwicklung einer GAI ein, um die Gefahren zu minimieren.

[Abhängigkeit]: Innerhalb kürzester Zeit nach der Entwicklung einer GAI wird unsere Zivilisation abhängig von ihr.

[Unmoralische Absichten]: Menschen mit schlechten Absichten können die GAI missbrauchen.

[Unkontrollierte Bereicherung]: Menschen, die die Kontrolle über eine GAI haben, erlangen unermesslichen Reichtum und folglich unermessliche Macht.

[Abschätzung der Gefahren]: Eine Abschätzung möglicher Gefahren ist schwer bis unmöglich. Deshalb wird die Erfindung einer GAI als Singularität bezeichnet.


[Zentrale These]
    +> [Neuralink]
    +> [extraterrestrische Zivilisation]
    +> [Einschränkung]
    <+ [Abhängigkeit]
    <+ [Unmoralische Absichten]
    <+ [Abschätzung der Gefahren]
